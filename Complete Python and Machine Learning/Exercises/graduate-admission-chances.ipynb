{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font size=\"+3\" color=red ><b> <center><u>Your chances to get into Graduate School</u></center></b></font><br><a id=\"top\"></a>\n",
    "<center><img src=\"https://blogs.colum.edu/marginalia/files/2017/03/screen-shot-2017-03-09-at-2.20.49-pm.png\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"toc\"></a>\n",
    "<div style=\"background: #f9f9f9 none repeat scroll 0 0;border: 1px solid #aaa;display: table;font-size: 95%;margin-bottom: 1em;padding: 20px;width: 600px;\">\n",
    "<h1>Contents</h1>\n",
    "<ul style=\"font-weight: 700;text-align: left;list-style: outside none none !important;\">\n",
    "<li style=\"list-style: outside none none !important;font-size:17px\"><a href=\"#1\">1 Introduction</a></li>\n",
    "    \n",
    "<li style=\"list-style: outside none none !important;font-size:17px\"><a href=\"#2\">2 Understanding data</a></li>\n",
    "\n",
    "<li style=\"list-style: outside none none !important;font-size:17px\"><a href=\"#3\">3 Data Analysis</a></li>\n",
    "     \n",
    "<li style=\"list-style: outside none none !important;font-size:17px\"><a href=\"#4\">4 Modelling</a></li>\n",
    "    <ul style=\"font-weight: 700;text-align: left;list-style: outside none none !important;\">  \n",
    "        <li style=\"list-style: outside none none !important;\"><a href=\"#4.1\">4.1 Regression</a></li>\n",
    "            <li style=\"list-style: outside none none !important;\"><a href=\"#4.2\">4.2 Classification</a></li>\n",
    "            <li style=\"list-style: outside none none !important;\"><a href=\"#4.3\">4.3 Blending</a></li>\n",
    "        \n",
    "\n",
    "</ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "7bcdaacfb7111fe7c5eb1342716baa939e12d5c3"
   },
   "source": [
    "# 1. Introduction\n",
    "<a class=\"anchor\" id=\"1\"></a>\n",
    "<a href=\"#toc\"><img src= \"https://upload.wikimedia.org/wikipedia/commons/thumb/2/20/Circle-icons-arrow-up.svg/1200px-Circle-icons-arrow-up.svg.png\" style=\"width:20px;hight:20px;float:left\" >        Back to the table of contents</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "e4c6abd4a9183e73fdb93c420e4d1c4423669607"
   },
   "source": [
    "This kernel mainly focuses on what parameters are important for a student to get into a graduate school.\n",
    "\n",
    "By the end of this kernel it will be clear of what are the scores required for different tests to have better admission chances and get into a good graduate school."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "sns.set_style('darkgrid')\n",
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "e41856eefb61d760ea4e1609c74241304b081f6c"
   },
   "source": [
    "# 2.Understanding Data\n",
    "<a class=\"anchor\" id=\"2\"></a>\n",
    "<a href=\"#toc\"><img src= \"https://upload.wikimedia.org/wikipedia/commons/thumb/2/20/Circle-icons-arrow-up.svg/1200px-Circle-icons-arrow-up.svg.png\" style=\"width:20px;hight:20px;float:left\" >        Back to the table of contents</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "0f57c32c0fcd880ca479b0ec181175b0c70971e3"
   },
   "outputs": [],
   "source": [
    "df=pd.read_csv('../input/Admission_Predict_Ver1.1.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c1c13edd1c4f36d54a22e1fdd730657059c43c02"
   },
   "source": [
    "Taking a look at our dataset for understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "c42132bde7373cae8ba35255dcd1966c0bf369e4"
   },
   "outputs": [],
   "source": [
    "df.head(10).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d39ed1d7a4ef93ed0e96a696c803b3cc0ce86c16"
   },
   "outputs": [],
   "source": [
    "df=df.rename(columns = {'Chance of Admit ':'Chance of Admit'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The column name `Chance of Admit` had a space at the end so I renamed it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "74efd52a85e445fca46fc93c11d57e54974a78ba"
   },
   "outputs": [],
   "source": [
    "l = df.columns\n",
    "print('The columns are: ',l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "5d2640f46d4e68d7401c26e8a87f1bf162194ceb"
   },
   "outputs": [],
   "source": [
    "print(df.isnull().sum())\n",
    "print('\\n\\nNo null values')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "3805512d0558c426432f976a3f61d448c3fb741f"
   },
   "outputs": [],
   "source": [
    "df.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "601335a0e86255fbfc44340676ee8b34a2ee6e0c"
   },
   "source": [
    "The above table gives us some intuition about all the columns and and some of their statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outlier Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a3f5a710a97e22dd846a916c2b3451067511f960"
   },
   "outputs": [],
   "source": [
    "def detect_outliers(df,n,features):\n",
    "    \"\"\"\n",
    "    Takes a dataframe df of features and returns a list of the indices\n",
    "    corresponding to the observations containing more than n outliers according\n",
    "    to the Tukey method.\n",
    "    \"\"\"\n",
    "    outlier_indices = []\n",
    "    \n",
    "    # iterate over features(columns)\n",
    "    for col in features:\n",
    "        # 1st quartile (25%)\n",
    "        Q1 = np.percentile(df[col], 25)\n",
    "        # 3rd quartile (75%)\n",
    "        Q3 = np.percentile(df[col],75)\n",
    "        # Interquartile range (IQR)\n",
    "        IQR = Q3 - Q1\n",
    "        \n",
    "        # outlier step\n",
    "        outlier_step = 1.5 * IQR\n",
    "        \n",
    "        # Determine a list of indices of outliers for feature col\n",
    "        outlier_list_col = df[(df[col] < Q1 - outlier_step) | (df[col] > Q3 + outlier_step )].index\n",
    "        \n",
    "        # append the found outlier indices for col to the list of outlier indices \n",
    "        outlier_indices.extend(outlier_list_col)\n",
    "        \n",
    "    # select observations containing more than 2 outliers\n",
    "    outlier_indices = Counter(outlier_indices)        \n",
    "    multiple_outliers = list( k for k, v in outlier_indices.items() if v > n )\n",
    "    \n",
    "    return multiple_outliers   \n",
    "outliers_to_drop=detect_outliers(df,2,['GRE Score', 'TOEFL Score', 'University Rating', 'SOP',\n",
    "       'LOR ', 'CGPA', 'Research'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "66ce6be5973eedc511aade40287d4dc8aa79cbbd"
   },
   "source": [
    "Since outliers can have a dramatic effect on the prediction (especially for regression problems), I chose to manage them.\n",
    "\n",
    "I used the Tukey method (Tukey JW., 1977) to detect ouliers which defines an interquartile range comprised between the 1st and 3rd quartile of the distribution values (IQR). An outlier is a row that have a feature value outside the (IQR +- an outlier step).\n",
    "\n",
    "I decided to detect outliers from the numerical values features (GRE Score, TOEFL Score, University Rating, SOP, LOR , CGPA, Research). Then, i considered outliers as rows that have at least two outlied numerical values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "9cc78de95298f9736f46c631e2333790364ad27a"
   },
   "outputs": [],
   "source": [
    "df.loc[outliers_to_drop] # Show the outliers rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "7380c8234ec7f3c002ff9bbc4190ddd9776b2f3c"
   },
   "source": [
    "There are no outliers because all the values are inside a fixed range and none of them go lower/beyond that range which therefore produces no outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "1bfdcbd8a346a1a353e178ec167bdd3c80fe2812"
   },
   "outputs": [],
   "source": [
    "cols=df.drop(labels='Serial No.',axis=1)\n",
    "cols.head().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "18ab5ad18ea984a8e703049fc1ae079ad268837a"
   },
   "source": [
    "# 3.Data Analysis\n",
    "<a class=\"anchor\" id=\"3\"></a>\n",
    "<a href=\"#toc\"><img src= \"https://upload.wikimedia.org/wikipedia/commons/thumb/2/20/Circle-icons-arrow-up.svg/1200px-Circle-icons-arrow-up.svg.png\" style=\"width:20px;hight:20px;float:left\" >        Back to the table of contents</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "147718e9dacb41f662ce3cbec858ea51cf06bced"
   },
   "outputs": [],
   "source": [
    "corr = cols.corr()\n",
    "mask = np.zeros_like(corr)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "with sns.axes_style(\"white\"):\n",
    "    f, ax = plt.subplots(figsize=(9, 7))\n",
    "    ax = sns.heatmap(corr,mask=mask,square=True,annot=True,fmt='0.2f',linewidths=.8,cmap=\"hsv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c0561b8825802b5f106d45d0388c9015954d60a6"
   },
   "source": [
    "Here we can see that the chance of admit is highly correlated with CGPA, GRE and TOEFEL scores are also correlated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "f869ced4f2549a9f75dc8de71d3db2a7c41abb9c"
   },
   "outputs": [],
   "source": [
    "plt.rcParams['axes.facecolor'] = \"#e6ffed\"\n",
    "plt.rcParams['figure.facecolor'] = \"#e6ffed\"\n",
    "g = sns.pairplot(data=cols,hue='Research',markers=[\"^\", \"v\"],palette='inferno')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "bf7fb4aa48d1de118dc87656877336959623f67e"
   },
   "source": [
    "Inferences from the above pairplot:\n",
    "* GRE score TOEFL score and CGPA all are linearly related to each other \n",
    "* Research Students tend to Score higher by all means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "5fc5eed1d173372fc7363fd23f0c858302694617"
   },
   "outputs": [],
   "source": [
    "plt.rcParams['axes.facecolor'] = \"#ffe5e5\"\n",
    "plt.rcParams['figure.facecolor'] = \"#ffe5e5\"\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.subplot(2, 1, 1)\n",
    "sns.distplot(df['GRE Score'],bins=34,color='Red',  kde_kws={\"color\": \"y\", \"lw\": 3, \"label\": \"KDE\"},hist_kws={\"linewidth\": 2,\"alpha\": 0.3 })\n",
    "plt.subplot(2, 1, 2)\n",
    "sns.distplot(df['TOEFL Score'],bins=12,color='Blue' ,kde_kws={\"color\": \"k\", \"lw\": 3, \"label\": \"KDE\"},hist_kws={\"linewidth\": 7,\"alpha\": 0.3 })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "cd47dd1292929de382f6e2972078e2ecd5c48da9"
   },
   "source": [
    "From the above 2 graphs its clear that people tend to score above 310 in GRE and above 100 in TOEFL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "b13175954f388390912f72eb799ff4ead434495d"
   },
   "outputs": [],
   "source": [
    "sns.scatterplot(x='University Rating',y='CGPA',data=df,color='Red', marker=\"^\", s=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "7e5f3efe3603a36766449ec0456d08ffe1629602"
   },
   "source": [
    "Ratings of university increase with the increase in the CGPA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "457ef4d05226190a39d0352ae2e081b1a026aeb1"
   },
   "source": [
    "## Now lets set some cut-off scores and try to analyse scores above the cut-off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "53b7ad83cf939e8c6fb2b4073105b3ed7f158bde"
   },
   "outputs": [],
   "source": [
    "co_gre=df[df[\"GRE Score\"]>=300]\n",
    "co_toefel=df[df[\"TOEFL Score\"]>=100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "d0cbc66f1b41eed04a662f37f7c24b610cf77392"
   },
   "outputs": [],
   "source": [
    "fig, ax = pyplot.subplots(figsize=(15,8))\n",
    "sns.barplot(x='GRE Score',y='Chance of Admit',data=co_gre, linewidth=1.5,edgecolor=\"0.1\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "1d5c371a82db283e25b38439405003f0303aa482"
   },
   "outputs": [],
   "source": [
    "fig, ax = pyplot.subplots(figsize=(15,8))\n",
    "sns.barplot(x='TOEFL Score',y='Chance of Admit',data=co_toefel, linewidth=3.5,edgecolor=\"0.8\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "0b12c1d9e143d5f2dbb7e7e123e583306637595c"
   },
   "source": [
    "The above two graphs make it clear that higher the Scores better the chance of admit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "6ee7eb0baccc8428c36568e9622796d482644da4"
   },
   "outputs": [],
   "source": [
    "s = df[df[\"Chance of Admit\"] >= 0.75][\"University Rating\"].value_counts().head(5)\n",
    "plt.title(\"University Ratings of Candidates with an 75% acceptance chance\")\n",
    "s.plot(kind='bar',figsize=(20, 10),linestyle='dashed',linewidth=5)\n",
    "plt.xlabel(\"University Rating\")\n",
    "plt.ylabel(\"Candidates\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "4fded2b58ee858a4928276bf2a2e8927683b044d"
   },
   "outputs": [],
   "source": [
    "print(\"Average GRE Score :{0:.2f} out of 340\".format(df['GRE Score'].mean()))\n",
    "print('Average TOEFL Score:{0:.2f} out of 120'.format(df['TOEFL Score'].mean()))\n",
    "print('Average CGPA:{0:.2f} out of 10'.format(df['CGPA'].mean()))\n",
    "print('Average Chance of getting admitted:{0:.2f}%'.format(df['Chance of Admit'].mean()*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "798dc809500977c5e852dec1264cd1036b1d045b"
   },
   "source": [
    "## Lets check out the toppers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "6a4de2dc53c70c10e9474fc960e8d5eebcdf539a"
   },
   "outputs": [],
   "source": [
    "toppers=df[(df['GRE Score']>=330) & (df['TOEFL Score']>=115) & (df['CGPA']>=9.5)].sort_values(by=['Chance of Admit'],ascending=False)\n",
    "toppers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "37a634809a816aed2e01931dc158019096c44d69"
   },
   "source": [
    "# 4.Modelling\n",
    "<a class=\"anchor\" id=\"4\"></a>\n",
    "<a href=\"#toc\"><img src= \"https://upload.wikimedia.org/wikipedia/commons/thumb/2/20/Circle-icons-arrow-up.svg/1200px-Circle-icons-arrow-up.svg.png\" style=\"width:20px;hight:20px;float:left\" >        Back to the table of contents</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "33c4e09b4f83e7500f855c78e063e86cd54ce0e9"
   },
   "source": [
    "Preparing the data for Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c5bc5bd69564968fc40e7dfd31b8652b54496053"
   },
   "outputs": [],
   "source": [
    "# reading the dataset\n",
    "df = pd.read_csv(\"../input/Admission_Predict.csv\",sep = \",\")\n",
    "\n",
    "# it may be needed in the future.\n",
    "serialNo = df[\"Serial No.\"].values\n",
    "\n",
    "df.drop([\"Serial No.\"],axis=1,inplace = True)\n",
    "\n",
    "df=df.rename(columns = {'Chance of Admit ':'Chance of Admit'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "07891939d1aac234d2c81a4b07e4fefcb5d56e91"
   },
   "outputs": [],
   "source": [
    "X=df.drop('Chance of Admit',axis=1)\n",
    "y=df['Chance of Admit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "612af99a549e056fe2bf76035d1c6859ee5836e4"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "\n",
    "#Normalisation works slightly better for Regression.\n",
    "X_norm=preprocessing.normalize(X)\n",
    "X_train,X_test,y_train,y_test=train_test_split(X_norm,y,test_size=0.20,random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "70201f3003ae2f6a80a27157b58c6fb4bba24b2d"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression,LogisticRegression\n",
    "from sklearn.tree import DecisionTreeRegressor,DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor,RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingRegressor,GradientBoostingClassifier\n",
    "from sklearn.ensemble import AdaBoostRegressor,AdaBoostClassifier\n",
    "from sklearn.ensemble import ExtraTreesRegressor,ExtraTreesClassifier\n",
    "from sklearn.neighbors import KNeighborsRegressor,KNeighborsClassifier\n",
    "from sklearn.svm import SVR,SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "from sklearn.metrics import accuracy_score,mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "634341e408aeda701e97d7a2fa37cd2f42f2535e"
   },
   "source": [
    "<a id=\"41\"></a> \n",
    "* Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ffb03616e0dcd33e4234ec74640ffd13c91529c9"
   },
   "outputs": [],
   "source": [
    "regressors=[['Linear Regression :',LinearRegression()],\n",
    "       ['Decision Tree Regression :',DecisionTreeRegressor()],\n",
    "       ['Random Forest Regression :',RandomForestRegressor()],\n",
    "       ['Gradient Boosting Regression :', GradientBoostingRegressor()],\n",
    "       ['Ada Boosting Regression :',AdaBoostRegressor()],\n",
    "       ['Extra Tree Regression :', ExtraTreesRegressor()],\n",
    "       ['K-Neighbors Regression :',KNeighborsRegressor()],\n",
    "       ['Support Vector Regression :',SVR()]]\n",
    "reg_pred=[]\n",
    "print('Results...\\n')\n",
    "for name,model in regressors:\n",
    "    model=model\n",
    "    model.fit(X_train,y_train)\n",
    "    predictions = model.predict(X_test)\n",
    "    rms=np.sqrt(mean_squared_error(y_test, predictions))\n",
    "    reg_pred.append(rms)\n",
    "    print(name,rms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "41fb107f87b81e9770472a96e9f52290e54abafa"
   },
   "outputs": [],
   "source": [
    "y_ax=['Linear Regression' ,'Decision Tree Regression', 'Random Forest Regression','Gradient Boosting Regression', 'Ada Boosting Regression','Extra Tree Regression' ,'K-Neighbors Regression', 'Support Vector Regression' ]\n",
    "x_ax=reg_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "aa4abfa043ad5abeaf17b6a98f8119ea349e3d65"
   },
   "outputs": [],
   "source": [
    "sns.barplot(x=x_ax,y=y_ax,linewidth=1.5,edgecolor=\"0.1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "50dbbe69659cdcf4c2833ff100be4bc42940bd88"
   },
   "source": [
    "<a id=\"42\"></a>\n",
    "* Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "fe7ace97c02420e6deb25d15f93af786a3ba4ebc"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.20,random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e5d2bb8d1eccf8c5bc13fad7049fc6d81275e869"
   },
   "outputs": [],
   "source": [
    "#If Chance of Admit greater than 80% we classify it as 1\n",
    "y_train_c = [1 if each > 0.8 else 0 for each in y_train]\n",
    "y_test_c  = [1 if each > 0.8 else 0 for each in y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e8d666d86cac4c997f2bd93433977c7ca65c8c11"
   },
   "outputs": [],
   "source": [
    "classifiers=[['Logistic Regression :',LogisticRegression()],\n",
    "       ['Decision Tree Classification :',DecisionTreeClassifier()],\n",
    "       ['Random Forest Classification :',RandomForestClassifier()],\n",
    "       ['Gradient Boosting Classification :', GradientBoostingClassifier()],\n",
    "       ['Ada Boosting Classification :',AdaBoostClassifier()],\n",
    "       ['Extra Tree Classification :', ExtraTreesClassifier()],\n",
    "       ['K-Neighbors Classification :',KNeighborsClassifier()],\n",
    "       ['Support Vector Classification :',SVC()],\n",
    "       ['Gausian Naive Bayes :',GaussianNB()]]\n",
    "cla_pred=[]\n",
    "for name,model in classifiers:\n",
    "    model=model\n",
    "    model.fit(X_train,y_train_c)\n",
    "    predictions = model.predict(X_test)\n",
    "    cla_pred.append(accuracy_score(y_test_c,predictions))\n",
    "    print(name,accuracy_score(y_test_c,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d52f4e3987516dd77b9969c21e3689219ae5023d"
   },
   "outputs": [],
   "source": [
    "y_ax=['Logistic Regression' ,\n",
    "      'Decision Tree Classifier',\n",
    "      'Random Forest Classifier',\n",
    "      'Gradient Boosting Classifier',\n",
    "      'Ada Boosting Classifier',\n",
    "      'Extra Tree Classifier' ,\n",
    "      'K-Neighbors Classifier',\n",
    "      'Support Vector Classifier',\n",
    "       'Gaussian Naive Bayes']\n",
    "x_ax=cla_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c7ad9f80468ea8d16c14998df771f60d060bb0cd"
   },
   "outputs": [],
   "source": [
    "sns.barplot(x=x_ax,y=y_ax,linewidth=1.5,edgecolor=\"0.8\")\n",
    "plt.xlabel('Accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b57f18a8d6330e200e975287716bf8b023d7ebcc"
   },
   "source": [
    "# So the winner in Regression is : **Linear Regression **\n",
    "# and the winner in Classification is :** Extra Tree Classifier**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<a href=\"#top\" class=\"btn btn-success btn-lg active\" role=\"button\" aria-pressed=\"true\" style=\"color:white\" data-toggle=\"popover\" title=\"go to Colors\">Go to TOP</a>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
